### 第1章-磁盘：最容易被忽略的性能洼地

#### 1.1 原理

**随机读/写**

> 1. 数据库的journal文件会导致随机写。当写操作在数据库的db文件和journal文件中来回发生时，则会发生随机写。
> 2. 如果向设置了autoincrement的数据库表中插入多条数据，那么每插入一条数据都需要操作两张数据库表，这就意味这存在随机写。

**为什么随机读/写会如此之慢**

> 1. 随机读会丢失预读(read-ahead)的优化效果。
> 2. 随机写相对顺序写除了产生大量的失效页面之外，更重要的是增加了触发"写入放大"效应的概率。

**写入放大**

> 当数据第一次写入时，由于所有的颗粒都为已清除状态，所以数据能够以页为最小单位直接写入进去。当有新的数据写入需要替换旧的数据时，主控制器将把新的数据写入到另外的空白闪存空间上，然后更新逻辑LBA地址来指向新的物理FTL地址。此时旧的地址内容就变成了无效的数据，但是主控制器并没有执行擦除操作而是标记对应的页为无效。当磁盘需要在上述无效区域再次进行写入的话，为了得到空闲空间，闪存必须先复制该块中的所有有效页到新的块中，并擦除旧的块，才能写入。
>
> 比如写入一个4k的数据，最坏的情况是一个块里没有干净空间了，但是恰好有一个页的无效数据可以擦除，所以主控就把所有的数据读出来，擦除快，再加上这个4k的新数据写回去。这样就造成了，其实只是想写入4kb的数据，结果造成了整个块512kb的写入操作。同时带来了原本只需要简单的写入4kb的操作变成了"闪存读取512k->缓存改4kb->闪存擦除512k->闪存写入512kb"。
>
> **出现的原因**
>
> - 外因：手机长期使用，磁盘空间不足。
> - 内因：应用触发大量随机写。

#### 1.2 工具集

|       工具        |               问题               |   能力    |
| :---------------: | :------------------------------: | :-------: |
| Systrace / Strace |     主线程IO，IO操作时间过长     |   发现    |
|    STRICT MODE    |             主线程IO             | 发现+定位 |
|    I/O Monitor    |  主线程IO，多余IO，Buffer过小等  | 发现+定位 |
|  SQL I/O Monitor  | 主线程IO，全表扫描，不合理事务等 | 发现+定位 |

- StrictMode

  > BlockGuardOs.pwrite方法中会调用BlockGuard.Policy.onWriteToDisk。而Policy是根据StrictMode.setThreadPolicy中的setThreadPolicy方法来设置，最后由AndroidBlockGuardPolicy处理onWriteToDisk。

- Perfbox:I/O Monitor：通过hook java层系统IO的方法，收集区分进程和场景的IO消息

  > 1. hook java 方法：参考Xposed。把系统IO方法指向native方法CallHandler->调用系统IO方法变成调用CallHandler->调用Java层回调函数beforehookedmethod->调用系统原有的对应的IO方法->调用回调方法afterhookedmethod。
  > 2. 区分进程和场景的IO信息收集：
  >    1. 替换app_process
  >    2. 将libfork.so添加到环境变量LD_PRELOAD中。libfork.so中实现了一个fork函数，当app_process通过fork函数启动zygote进程时，会调用libfork.so中的fork函数
  >    3. 将XPlatform.jar添加到环境变量classpath中。如果不加入classpath中，需要使用dexclassloader来使用另一个jar包中的类。
  >    4. 区分场景的IO信息收集

- SQL I/O Monitor

  > 无论是优化表结构，使用索引，增加缓存，调整page size等，最终目的都是减少磁盘IO。
  >
  > 1. 采集数据库IO次数：native hook由缺陷，可以hook应用代码的数据库操作。
  > 2. Hook应用层SQL操作，Java层基于xposed方法实现。

#### 1.3 案例A：手机QQ启动有10次重复读写/proc/cpuinfo

每次打开关闭或者读写文件，操作系统都会从用户态切换到内核态，所以为了提高文件的读写效率，需要尽量减少用户态和内核态的切换。使用缓存可以避免重复读写。

#### 1.4 案例B：对于系统API，只知其一造成重复写入

SharedPreference每调用一次commit，就会对应一次文件的打开和关闭，从而造成因commit方法的随意调用而导致文件的重复打开和关闭。

#### 1.5 案例C：手机QQ启动场景下主线程写文件

将IO放到子线程中是第一步，更重要的是如后面案例一样，真正减少IO甚至避免IO

#### 1.6 案例D：ObjectOutputStream 4000多次的写操作

ObjectOutputStream在保存对象时，每个数据成员会带来一次IO操作。**解决方法是再封装一个ByteArrayOutputStream（或者BufferedOutputStream），先将对象序列化后的信息写入到缓存区，然后再一次性写入到磁盘**。

**对于使用ObjectOutputStream/OutputInputStream来保存和读取对象时，尽量使用Buffered和ByteArrayStream来减少IO次数**。

#### 1.7 案例E：手机QQ健康中心的使用Buffer太小

- buffer不能大于文件大小（一般至少为4kb，推荐为8kb），buffer太大会导致申请buffer的时间变长。
- buffer size根据文件挂载目录的block size来确定buffer大小，而数据库的pagesize就是这样确定的。

#### 1.8 案例F：手机QQ解压文件使用buffer太小

Android提供了两种解压zip文件方法：ZipInputStream和ZipFile

1. ZipInputStream

   > 流式来顺序访问zip，当读到某个文件结尾时(Entry)返回-1，通过getNextEntry来判断是否要继续往下读。
   >
   > InflaterInputStream.read方法返回的count并不是我们传入的buffer的大小，而是取决于inflate解压返回的数据(Android 4.4)

2. ZipFile

   > ZipFile通过RandomAccessFile随机访问ZIP文件，通过Central Directory得到ZIP中所有的Entry，Entry包含文件开始位置和size。前期读Central Directory可能会浪费一点时间，但是后面可以利用RandomAccessFile的特性，每次读入更多数据来提高解压效率。
   >
   > ZipFile定义了两个类，RAFStream和ZipInflaterInputStream。
   >
   > ZipFile的读文件是在native层进行的，每次读文件的大小是Math.max(1024,65535L)；ZipInputStream每次处理的数据只有512字节。（Android 4.4）

3. ZipFile vs ZipInputStream效率对比

   - ZipFile与ZipInputStream相比，耗时减少15%~22%
   - 与不使用buffer相比，ZipInputStream的耗时减少14%~62%，ZipFile解压低压缩率文件耗时有6%的减少，但是高压缩率有9%的增加（虽然减少了write次数，但是为了凑满Buffer，增加了read的调用次数）。

4. 结论

   - 如果文件已保存在磁盘上，且解压所有的文件，使用ZipFile
   - 仅解压某些文件，使用ZipFile
   - 如果Zip没有在磁盘上或者顺序解压一小部分文件，又或者ZIP文件目录遭到损坏，建议使用ZipInputStream。

#### 1.9 案例G：刚创建好表，就做大量的查询操作

解决方案：

- 新创建的表为空时，不要去做无谓的查询操作
- 对于覆盖安装，在表已经存在的情况下，使用INSERT OR REPLACE语句来完成插入。

#### 1.10 案例H：重复打开数据库

打开数据库操作比较耗时，Android本身会有缓存。但是每次打开数据库，同时会有一些IO操作，不能在主线程进行。

#### 1.11 案例I：AUTOINCREMENT可没有你想的那么简单

> sqlite表的每行都有一个行号，行号用64位有符号的整数表示。sqlite支持使用默认的列名ROWID和OID来访问行号。
>
> 1. 数据库引擎选择的行号会比所有之前用过的行号都大，即使数据被删除，行号也不会被复用。
> 2. 如果行号的最大值被用过，插入新数据时，会报SQLITE_FULL错误。
>
> SQLite创建一个叫sqlite_sequence的内部表来记录该表使用的最大行号。autoincrement会使写磁盘的次数由2次增加到11次。

#### 1.12 案例J：bitmap解码

> 使用decodeStream代替decodeFile，decodeResourceStream代替decodeResource，并且传入的流应该是bufferedinputstream







